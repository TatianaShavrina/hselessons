{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hittite language transliteration Shavrina\n",
    "\n",
    "На сервере в home/guest1/2017/Shavrina/hettencode.py\n",
    "\n",
    "Использование: python hettencode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "import argparse\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_html(syllab_file):\n",
    "    file = open(syllab_file, \"r\", encoding=\"utf8\").read()\n",
    "    syllabtext = []\n",
    "    htmlhead = re.split('<body lang=\"ru-RU\" dir=\"ltr\">', file)[0]\n",
    "    htmlbody = re.split('</p>', re.split(\"<div id=\", file)[0])\n",
    "    for i in range (len(htmlbody)):\n",
    "        htmlbody[i] = re.sub(\"</span></font></sup>\",\"<separator>\",htmlbody[i])\n",
    "        htmlbody[i] = re.sub(\"</span></font></sub>\",\"<separator>\",htmlbody[i])\n",
    "        htmlbody[i] = re.sub(\"</span></font>\",\"<separator>\",htmlbody[i])\n",
    "        lst = re.split(\"<separator>\",htmlbody[i])\n",
    "        for y in lst:\n",
    "            if \"remaining\" not in y or \"missing\" not in y :\n",
    "                syllabtext.append(y)\n",
    "    htmlbottom = \"</p>\\n</body>\\n</html>\" #отрезаем комментарии\n",
    "    for i in range(len(syllabtext)):\n",
    "        if '<a class=' in syllabtext[i]:\n",
    "            syllabtext[i] = \"\".join([re.split(\"<a class=\",syllabtext[i])[0], \"'\"]) #отрезаем сноски\n",
    "\n",
    "    return syllabtext,htmlhead,htmlbottom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vowels = ['aeiuAEIU']\n",
    "\n",
    "def token_lang(token,cleantoken):\n",
    "    #определяем язык слова \n",
    "    \n",
    "    if \"<i>\" in token:\n",
    "        lang = 'akkad'\n",
    "    elif cleantoken.isupper():\n",
    "        lang = 'shumer'\n",
    "    else:\n",
    "        lang = 'hett' #default\n",
    "    return (lang)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def script(token):\n",
    "    #определяем написание\n",
    "    script_type = 'normal'\n",
    "    if '<sup>' in token:\n",
    "        script_type = 'superscript'\n",
    "    elif '<sub>' in token:\n",
    "        script_type = 'subscript'     \n",
    "    return(script_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_token(token): #только само хеттское слово, без тегов\n",
    "    fin = re.sub(\"'\",\"\", token)\n",
    "    fin = re.sub('</i>',\"\", fin)\n",
    "    cleantoken1 = re.split(\">\",fin)\n",
    "    cleantoken = cleantoken1[-1]\n",
    "    return(cleantoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_feat(token):\n",
    "    try:\n",
    "        fontsize = re.split('\"', re.split('<font size=\"', token)[1])[0]\n",
    "        style = re.split('\"', re.split('style=\"', token)[1])[0]\n",
    "        spanlang = re.split('\"', re.split('<span lang=\"', token)[1])[0]\n",
    "        return(fontsize, spanlang, style)\n",
    "    except:\n",
    "        fontsize = 2\n",
    "        spanlang = \"it-IT\"\n",
    "        style = \"font-size: 9pt\"\n",
    "        return(fontsize, spanlang, style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lonely_vowels(i,cleantoken):\n",
    "    if i==0 and len(cleantoken)>1 and cleantoken[i+1]==\"-\":\n",
    "        features=\"lonely,start\"\n",
    "    elif i==(len(cleantoken)-1) and cleantoken[i-1]==\"-\":\n",
    "        features=\"lonely,end\"\n",
    "    elif cleantoken[i-1]==\"-\" and cleantoken[i+1]==\"-\":\n",
    "        features=\"lonely,mid\"\n",
    "    else:\n",
    "        features=\"notlonely\"\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def operations(token_dict):\n",
    "    j=0\n",
    "    new_dict = {}\n",
    "    garbage = ['*', '~','!', '?', '[', ']', '˹', '˺', '˼', '˻']\n",
    "    l = len(token_dict)\n",
    "    for i in range(l):\n",
    "        if token_dict[i][0]==\"-\":\n",
    "            if i>0 and i<l-1:\n",
    "                if  token_dict[i-1][2]==token_dict[i+1][2]:\n",
    "                    token_dict[i][0]=re.sub('-','',token_dict[i][0])\n",
    "                    new_dict[j] = token_dict[i]\n",
    "                    j+=1\n",
    "                \n",
    "            else:\n",
    "                new_dict[j] = token_dict[i]\n",
    "                j+=1\n",
    "\n",
    "        elif token_dict[i][2]=='hett':\n",
    "            if token_dict[i][0]=='í':\n",
    "                token_dict[i][0]=re.sub('í','i',token_dict[i][0])\n",
    "                new_dict[j] = token_dict[i]\n",
    "                j+=1\n",
    "            elif token_dict[i][1]=='subscript':\n",
    "                pass\n",
    "            \n",
    "\n",
    "\n",
    "        elif token_dict[i][0]=='i':\n",
    "            if i>0 and i<l-1:\n",
    "                if  token_dict[i-1][0] in vowels :\n",
    "                    if token_dict[i+1][0] in vowels:\n",
    "                        token_dict[i][0]=re.sub('i','y',token_dict[i][0])\n",
    "                        new_dict[j] = token_dict[i]\n",
    "                        j+=1\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        elif token_dict[i][0] in garbage:\n",
    "            token_dict[i][0]=''\n",
    "            new_dict[j] = token_dict[i]\n",
    "            j+=1\n",
    "        \n",
    "        elif token_dict[i][0].isalpha()==False:\n",
    "            if token_dict[i][0]==\"\\n\":\n",
    "                new_dict[j] = token_dict[i]\n",
    "                j+=1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        elif token_dict[i][0]=='h':\n",
    "            token_dict[i][0]=re.sub('h','ḫ',token_dict[i][0])\n",
    "            new_dict[j] = token_dict[i]\n",
    "            j+=1\n",
    "\n",
    "        elif token_dict[i][0]=='s':\n",
    "            token_dict[i][0]=re.sub('s','š',token_dict[i][0])\n",
    "            new_dict[j] = token_dict[i]\n",
    "            j+=1\n",
    "            \n",
    "\n",
    "        \n",
    "        elif token_dict[i][0] in vowels :\n",
    "                if token_dict[i+1][0]==token_dict[i][0]:\n",
    "                    if i==0 or i==len((token_dict)-1):  #абс конец и начало\n",
    "                        token_dict[i][0] = re.sub('a','ā',token_dict[i][0])\n",
    "                        token_dict[i][0] = re.sub('u','ū',token_dict[i][0])\n",
    "                        token_dict[i][0] = re.sub('e','ē',token_dict[i][0])\n",
    "                        token_dict[i][0] = re.sub('i','ī',token_dict[i][0])\n",
    "                        token_dict[i+1][0] = re.sub(token_dict[i+1][0],'',token_dict[i+1][0])\n",
    "                        new_dict[j] = token_dict[i]\n",
    "                        i+=1\n",
    "                        j+=1\n",
    "                    elif token_dict[i][4].startswith('lonely') or token_dict[i+1][4].startswith('lonely'):\n",
    "                        new_dict[j] = token_dict[i]\n",
    "                        j+=1\n",
    "                    elif token_dict[i+2][0]==token_dict[i][0]:\n",
    "\n",
    "                        token_dict[i][0] = re.sub('a','ā',token_dict[i][0])\n",
    "                        token_dict[i][0] = re.sub('u','ū',token_dict[i][0])\n",
    "                        token_dict[i][0] = re.sub('e','ē',token_dict[i][0])\n",
    "                        token_dict[i][0] = re.sub('i','ī',token_dict[i][0])\n",
    "                        token_dict[i+1][0] = ''\n",
    "                        token_dict[i+2][0] = ''\n",
    "                        new_dict[j] = token_dict[i]\n",
    "                        i+=2\n",
    "                        j+=1\n",
    "                    else:\n",
    "                        token_dict[i][0]=\"\" #смотрим только вперед, остается только вторая гласная\n",
    "                        new_dict[j] = token_dict[i]\n",
    "                        j+=1\n",
    "                        i+=1\n",
    "                else:\n",
    "                    new_dict[j] = token_dict[i]\n",
    "                    j+=1\n",
    "\n",
    "        else:\n",
    "            new_dict[j] = token_dict[i]\n",
    "            j+=1\n",
    "        \n",
    "    return(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore_token(token,lang,script_type,html):\n",
    "    # сначала разные языки букв\n",
    "    restored_token = token\n",
    "    if lang =='akkad':\n",
    "        \n",
    "        restored_token= '<font size=\"' + str(html[0]) + ' style=' + html[2] + '\"><span lang=\"' + html[1] + '\">' + \"<i>\" + restored_token + \"</i>\" + '</span></font>'\n",
    "    else:\n",
    "        restored_token = '<font size=\"' + str(html[0]) + ' style=' + html[2] + '\"><span lang=\"' + html[1] + '\">' + restored_token + '</span></font>'\n",
    "            \n",
    "    if script_type == '<sup>':\n",
    "        restored_token=\"<sup>\" + restored_token + \"</sup>\"\n",
    "    elif script_type == '<sub>':\n",
    "        restored_token=\"<sub>\" + restored_token + \"</sub>\"\n",
    "    return(restored_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def syll_to_short(syllabtext):\n",
    "    shorttext = []\n",
    "\n",
    "    #сделаем из каждого токена словарь, ключом которого будет порядковый номер буквы,\n",
    "    # а значениями - сама буква и ее признаки: язык, одиноч и ее позиция, суперскрипт/субскрипт, html\n",
    "    for token in syllabtext:\n",
    "    \n",
    "        token_dict = {}\n",
    "        \n",
    "        cleantoken = clean_token(token)\n",
    "        if len(cleantoken)>0:\n",
    "\n",
    "            for j in range(len(cleantoken)):\n",
    "                if cleantoken[j] in vowels:\n",
    "                    features = lonely_vowels(j,cleantoken)\n",
    "                else:\n",
    "                    features = \"cons\" \n",
    "                token_dict[j] = [cleantoken[j], script(token), token_lang(token,cleantoken),  html_feat(token), features]\n",
    "\n",
    "            new_dic = operations(token_dict)\n",
    "            #print(new_dic)\n",
    "\n",
    "            word = \"\"\n",
    "            for i in range(len(new_dic)):\n",
    "                word += new_dic[i][0]\n",
    "\n",
    "                lang, script1, html = new_dic[i][2], new_dic[i][1], new_dic[i][3]\n",
    "\n",
    "            new = restore_token(word, lang, script1, html)\n",
    "            word = \"\"\n",
    "            shorttext.append(new)\n",
    "            \n",
    "    return (shorttext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_html(syllab_file, short_file):\n",
    "    syllabtext,htmlhead,htmlbottom = read_html(syllab_file)\n",
    "\n",
    "    htmlhead += '<body lang=\"ru-RU\" dir=\"ltr\">\\n'\n",
    "    shorttext = syll_to_short(syllabtext)\n",
    "    html = htmlhead\n",
    "    for i in range(len(shorttext)):\n",
    "        html += shorttext[i]\n",
    "    html += htmlbottom\n",
    "    outfile = open(short_file, \"w\", encoding=\"utf8\")\n",
    "    outfile.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #args = parser.parse_args()\n",
    "    #if len(args) != 2:\n",
    "        #sys.exit(\"Использование: python hettencode.py syllab_file short_file\")\n",
    "    #syllab_file, short_file = args\n",
    "    syllab_file = r\"C:\\Users\\USER\\Documents\\hse\\progr\\syllab1.html\"\n",
    "    short_file = r\"C:\\Users\\USER\\Documents\\hse\\progr\\syllab1_short.html\"\n",
    "    create_html(syllab_file, short_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is my hw4 - Task 1: Affect in Tweets\n",
    "#### Tatiana Shavrina\n",
    "\n",
    "More specificly, I used the data from EI-reg for English\n",
    "#### Task EI-reg: Detecting Emotion Intensity (regression)\n",
    "\n",
    "#### The task is formulated:\n",
    "determine the intensity or amount of X felt by the speakerâ€”a real-valued score between 0 and 1:\n",
    "a score of 1: speaker feels the highest amount of X\n",
    "a score of 0: speaker feels the lowest amount of X\n",
    "\n",
    "#### Data:\n",
    "for each tweet\n",
    "a tweet\n",
    "an affect category X (anger, fear, joy, or sadness)\n",
    "\n",
    "I am using training data as a training data, and developers data provided - as a test set\n",
    "I've put the pandas-transformed data into archive with password, you can find it here:\n",
    "\n",
    "#### Compatability:\n",
    "if you are using Linux, change all the filepath slaches from '\\\\' to '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "\n",
    "import pandas as pd\n",
    "import os, re\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def txt_to_dataframe(lst):\n",
    "    textid,text,emo,weight=[],[],[],[]\n",
    "    for filename in lst:\n",
    "        file = open(filename, 'r', encoding='utf8').readlines()\n",
    "        textid = textid+[line.split('\\t')[0] for line in file if '\\t' in line]\n",
    "        text = text+[line.split('\\t')[1] for line in file if '\\t' in line]\n",
    "        emo = emo+[line.split('\\t')[2] for line in file if '\\t' in line]\n",
    "        weight = weight+[line.split('\\t')[3].strip('\\n') for line in file if '\\t' in line]\n",
    "    data = pd.DataFrame(\n",
    "    {'textid': textid,\n",
    "     'text': text,\n",
    "     'emo': emo,\n",
    "     'weight': weight\n",
    "    })\n",
    "    \n",
    "    data = shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = [],[]\n",
    "workdir = r'C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train'\n",
    "for file in os.listdir(workdir):\n",
    "    if '2018-EI-reg' in file:\n",
    "        if \"dev\" in file:\n",
    "            test.append(workdir+'\\\\'+file)\n",
    "        else:\n",
    "            train.append(workdir+'\\\\'+file)\n",
    "test, train = txt_to_dataframe(test),txt_to_dataframe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emo</th>\n",
       "      <th>text</th>\n",
       "      <th>textid</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>joy</td>\n",
       "      <td>I finally left the dark room I've been crying ...</td>\n",
       "      <td>2018-en-joy-dev-27</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>sadness</td>\n",
       "      <td>If you are going to be a nurse, learn to be a ...</td>\n",
       "      <td>2018-en-sadness-dev-58</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Chopper &amp;lt;&amp;lt;Dammit! Just sink already!&amp;gt;...</td>\n",
       "      <td>2018-en-sadness-dev-163</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>anger</td>\n",
       "      <td>@mickyrivera29 interesting but a transfer too ...</td>\n",
       "      <td>2018-en-anger-dev-122</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>fear</td>\n",
       "      <td>I'm back on Twitter! #madden #madden18 #madden...</td>\n",
       "      <td>2018-en-fear-dev-12</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         emo                                               text  \\\n",
       "426      joy  I finally left the dark room I've been crying ...   \n",
       "657  sadness  If you are going to be a nurse, learn to be a ...   \n",
       "762  sadness  Chopper &lt;&lt;Dammit! Just sink already!&gt;...   \n",
       "121    anger  @mickyrivera29 interesting but a transfer too ...   \n",
       "211     fear  I'm back on Twitter! #madden #madden18 #madden...   \n",
       "\n",
       "                      textid weight  \n",
       "426       2018-en-joy-dev-27  0.242  \n",
       "657   2018-en-sadness-dev-58  0.413  \n",
       "762  2018-en-sadness-dev-163  0.304  \n",
       "121    2018-en-anger-dev-122  0.578  \n",
       "211      2018-en-fear-dev-12  0.125  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emo</th>\n",
       "      <th>text</th>\n",
       "      <th>textid</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [emo, text, textid, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: emo, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.emo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv(path_or_buf=r'C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\test.csv', sep='\\t',encoding='utf8')\n",
    "train.to_csv(path_or_buf=r'C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\train.csv', sep='\\t',encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On our data, we can see that the classification is not multiclass, while hashtags show  the opposite \n",
    "\n",
    "10003\tso ef whichever butt wipe pulled the fire alarm in davis bc I was sound asleep #pissed #angry #upset #tired #sad #tired #hangry ######\tanger\t0.896\n",
    "\n",
    "####  imho, this is  a serious reason for the deterioration of classification quality, because this way  the data is not clean itself. Although the data is never clean :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build a classifier on that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, Ridge, LinearRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we will assume, that in the test data we already have emotional class - fear, anger , joy or sadness - because they are obviously got from hashtags, and we have these hashtags in the tweets. So we should train 4 classifiers for each emotion to predict the affect from 0 to 1 in a given emotion.\n",
    "#### This is easy to do with regression analysis on text features - let's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,5), analyzer='word', max_features=20000)),\n",
    "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "    #('reducer', TruncatedSVD(n_components=Val3)),\n",
    "    ('clf', Ridge(fit_intercept=False, random_state = 0))])\n",
    "b = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,5), analyzer='word', max_features=20000)),\n",
    "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "    #('reducer', TruncatedSVD(n_components=Val3)),\n",
    "    ('clf', LinearRegression(n_jobs =-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintestsplit(train, test, emot):\n",
    "    X_train = [train.text.iloc[i] for i in range (len(train)) if train.emo.iloc[i]==emot]\n",
    "    y_train = [float(train.weight.iloc[i]) for i in range (len(train)) if train.emo.iloc[i]==emot]\n",
    "    X_test = [test.text.iloc[i] for i in range (len(test)) if test.emo.iloc[i]==emot]\n",
    "    y_test = [float(test.weight.iloc[i]) for i in range (len(test)) if test.emo.iloc[i]==emot]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To test the obtained quality we will use evaluation script from\n",
    "https://github.com/felipebravom/EmoInt\n",
    "\n",
    "I slightly changed the code as it is suitable for python 2, and I am using python3 + I changed the output format\n",
    "See https://github.com/TatianaShavrina/hselessons/blob/master/AffectTweets.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emot in set(train.emo.values):\n",
    "    outfile = open(workdir+'\\\\'+emot+'-pred.txt', 'w', encoding='utf8')\n",
    "    testfile = open(workdir+'\\\\'+emot+'-gold.txt', 'w', encoding='utf8')\n",
    "    X_train, y_train, X_test, y_test = traintestsplit(train, test, emot)\n",
    "    a.fit(X_train, y_train)\n",
    "    b.fit(X_train, y_train)\n",
    "    predictions_a = [round(y,3) for y in a.predict(X_test)]\n",
    "    predictions_b = [round(y,3) for y in b.predict(X_test)]\n",
    "    \n",
    "    outfile.close()\n",
    "    testfile.close()\n",
    "    print('linear regression on words')\n",
    "    print('predicting '+emot)\n",
    "    print(\"Mean absolute error regression loss \", str(mean_absolute_error(y_test, predictions_b)))\n",
    "    print(\"Mean squared error regression loss \", str(mean_squared_error(y_test, predictions_b)))\n",
    "    print(\"Mean squared logarithmic error regression loss \", str(mean_squared_log_error(y_test, predictions_b)))\n",
    "    print(\"Median absolute error regression loss \",str(median_absolute_error(y_test, predictions_b)))\n",
    "    print(\"r2_score\", str(r2_score(y_test, predictions_b)))\n",
    "    print()\n",
    "    print('Ridge regression on words')\n",
    "    print('predicting '+emot)\n",
    "    print(\"Mean absolute error regression loss \", str(mean_absolute_error(y_test, predictions_a)))\n",
    "    print(\"Mean squared error regression loss \", str(mean_squared_error(y_test, predictions_a)))\n",
    "    print(\"Mean squared logarithmic error regression loss \", str(mean_squared_log_error(y_test, predictions_a)))\n",
    "    print(\"Median absolute error regression loss \",str(median_absolute_error(y_test, predictions_a)))\n",
    "    print(\"r2_score\", str(r2_score(y_test, predictions_a)))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression seems a lot better! Let's save the model so that it could be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Shavrina_T\\\\Documents\\\\other\\\\EI-reg-English-Train\\\\ridge.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname = workdir +'\\\\ridge.pkl'\n",
    "joblib.dump(a, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emot in set(train.emo.values):\n",
    "    outfile = open(workdir+'\\\\'+emot+'-pred.txt', 'w', encoding='utf8')\n",
    "    testfile = open(workdir+'\\\\'+emot+'-gold.txt', 'w', encoding='utf8')\n",
    "    X_train, y_train, X_test, y_test = traintestsplit(train, test, emot)\n",
    "    a.fit(X_train, y_train)\n",
    "    for i in range(len(test)):\n",
    "        ls1=[test.textid.iloc[i],test.text.iloc[i],test.emo.iloc[i]]\n",
    "        ls2=[test.textid.iloc[i],test.text.iloc[i],test.emo.iloc[i],test.weight.iloc[i]]\n",
    "        \n",
    "        e = a.predict([test.text.iloc[i]])\n",
    "        ls1.append(str(round(e[0],3)))\n",
    "        outfile.write('\\t'.join(ls1)+'\\n')\n",
    "        testfile.write('\\t'.join(ls2)+'\\n')\n",
    "    outfile.close()\n",
    "    testfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-gold.txt:\t0.0628256437243\n",
      "Spearman correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-gold.txt:\t0.0682795805942\n",
      "Pearson correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-gold.txt:\t0.0637663047328\n",
      "Spearman correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-gold.txt:\t0.0558755151785\n",
      "Pearson correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-gold.txt:\t0.177423338869\n",
      "Spearman correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-gold.txt:\t0.180673680582\n",
      "Pearson correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-gold.txt:\t0.153503289938\n",
      "Spearman correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-gold.txt:\t0.158950216305\n",
      "Pearson correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-gold.txt:\t0.0225667552017\n",
      "Spearman correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-gold.txt:\t0.0339692866333\n",
      "Pearson correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-gold.txt:\t0.10248926388\n",
      "Spearman correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-gold.txt:\t0.120129487917\n",
      "Pearson correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-gold.txt:\t0.093918294638\n",
      "Spearman correlation between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-gold.txt:\t0.0976067300438\n",
      "Pearson correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-gold.txt:\t0.128375576413\n",
      "Spearman correlation for gold scores in range 0.5-1 between C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-pred.txt and C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-gold.txt:\t0.129735487123\n",
      "\n",
      "Average Pearson correlation:\t0.0891835081081\n",
      "Average Spearman correlation:\t0.0951323194633\n",
      "Average Pearson correlation for gold scores in range 0.5-1:\t0.112033608741\n",
      "Average Spearman correlationfor gold scores in range 0.5-1:\t0.116172676631\n"
     ]
    }
   ],
   "source": [
    "#! evaluate.py 1 anger-pred.txt anger-pred.txt\n",
    "!python evaluate.py 4 C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-pred.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\anger-gold.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-pred.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\fear-gold.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-pred.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\joy-gold.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-pred.txt C:\\Users\\Shavrina_T\\Documents\\other\\EI-reg-English-Train\\sadness-gold.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
